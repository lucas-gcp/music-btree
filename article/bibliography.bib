@book{clrs:22,
	address = {Cambridge, Massachusetts London},
	edition = {4th},
	title = {Introduction to algorithms},
	isbn = {9780262046305 9780262367509},
	abstract = {A comprehensive update of the leading algorithms text, with new material on matchings in bipartite graphs, online algorithms, machine learning, and other topics. Some books on algorithms are rigorous but incomplete; others cover masses of material but lack rigor. Introduction to Algorithms uniquely combines rigor and comprehensiveness. It covers a broad range of algorithms in depth, yet makes their design and analysis accessible to all levels of readers, with self-contained chapters and algorithms in pseudocode. Since the publication of the first edition, Introduction to Algorithms has become the leading algorithms text in universities worldwide as well as the standard reference for professionals. This fourth edition has been updated throughout. New for the fourth edition New chapters on matchings in bipartite graphs, online algorithms, and machine learning New material on topics including solving recurrence equations, hash tables, potential functions, and suffix arrays 140 new exercises and 22 new problems Reader feedback-informed improvements to old problems Clearer, more personal, and gender-neutral writing style Color added to improve visual presentation Notes, bibliography, and index updated to reflect developments in the field Website with new supplementary material},
	language = {eng},
	publisher = {The MIT Press},
	author = {Cormen, Thomas H. and Leiserson, Charles Eric and Rivest, Ronald Linn and Stein, Clifford},
	year = {2022},
}

@misc{Pm:10,
  author = {Kerttu Pollari-Malmi},
  title = {B+-Trees},
  institution = {University of Helsinki},
  howpublished = {\url{https://www.cs.helsinki.fi/u/mluukkai/tirak2010/B-tree.pdf}},
  year = {2010},
}

@article{Co:79,
  author = {Comer, Douglas},
  title = {Ubiquitous {B}-Tree},
  year = {1979},
  issue_date = {June 1979},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {11},
  number = {2},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/356770.356776},
  doi = {10.1145/356770.356776},
  journal = {ACM Computing Surveys},
  month = jun,
  pages = {121-137},
  numpages = {17}
}


@book{Kn:98,
  author = {Knuth, Donald E.},
  title = {The Art of Computer Programming, Volume 3: Sorting and Searching},
  edition = {2nd},
  year = {1998},
  isbn = {0201896850},
  publisher = {Addison Wesley Longman Publishing Co., Inc.},
  address = {USA}
}

@book{SwMa:10,
  author = {Jayme Luiz Szwarcfiter and Lilian Markenzon},
  title = {Estruturas de Dados e Seus Algoritmos},
  year = {2010},
  edition = {3rd},
  isbn = {978-85-216-2994-8},
  publisher = {LTC},
  address = {Rio de Janeiro, RJ}
}

@article{Bl:25,
    author = {Blakeley, Ryan},
    title = {Mozart and Metadata: Classical Music in the Streaming Age},
    journal = {Journal of Musicology},
    volume = {42},
    number = {3},
    pages = {253-285},
    year = {2025},
    month = {07},
    issn = {0277-9269},
    doi = {10.1525/jm.2025.42.3.253},
    url = {https://doi.org/10.1525/jm.2025.42.3.253},
    eprint = {https://online.ucpress.edu/jm/article-pdf/42/3/253/889085/jm.2025.42.3.253.pdf},
}

@article{NaRaRuMa:09,
author = {Alexandros Nanopoulos and Dimitrios Rafailidis and Maria M. Ruxanda and Yannis Manolopoulos},
title = {Music search engines: Specifications and challenges},
journal = {Information Processing \& Management},
volume = {45},
number = {3},
pages = {392-396},
year = {2009},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2009.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0306457309000120},
}


@inproceedings{LiThChToGa:19,
author = {Li, Ang and Thom, Jennifer and Chandar, Praveen and Hosey, Christine and Thomas, Brian St. and Garcia-Gathright, Jean},
title = {Search Mindsets: Understanding Focused and Non-Focused Information Seeking in Music Search},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3313627},
doi = {10.1145/3308558.3313627},
abstract = {Music listening is a commonplace activity that has transformed as users engage with online streaming platforms. When presented with anytime, anywhere access to a vast catalog of music, users face challenges in searching for what they want to hear. We propose that users who engage in domain-specific search (e.g., music search) have different information-seeking needs than in general search. Using a mixed-method approach that combines a large-scale user survey with behavior data analyses, we describe the construct of search mindset on a leading online streaming music platform and then investigate two types of search mindsets: focused, where a user is looking for one thing in particular, and non-focused, where a user is open to different results. Our results reveal that searches in the music domain are more likely to be focused than non-focused. In addition, users' behavior (e.g., clicks, streams, querying, etc.) on a music search system is influenced by their search mindset. Finally, we propose design implications for music search systems to best support their users.},
booktitle = {The World Wide Web Conference},
pages = {2971–2977},
numpages = {7},
keywords = {music search, mixed methods, information need},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@article{MoVi:18,
  title={Música na era do <i>streaming</i>: curadoria e descoberta musical no Spotify},
  volume={20},
  ISSN={1517-4522},
  url={https://doi.org/10.1590/15174522-02004911},
  DOI={10.1590/15174522-02004911},
  number={49},
  journal={Sociologias},
  publisher={Programa de Pós-Graduação em Sociologia - UFRGS},
  author={Moschetta, Pedro Henrique and Vieira, Jorge},
  year={2018},
  month={Sep},
  pages={258–292}
}

@misc{MaRa:22,
  title={Pied Piper: Meta Search for Music}, 
  author={Pulak Malhotra and Ashwin Rao},
  year={2022},
  eprint={2211.07610},
  archivePrefix={arXiv},
  primaryClass={cs.IR},
  url={https://arxiv.org/abs/2211.07610%7D}, 
}

@article{Ba+:20,
  author = {B\'{a}ez-Su\'{a}rez, Abraham and Shah, Nolan and Nolazco-Flores, Juan Arturo and Huang, Shou-Hsuan S. and Gnawali, Omprakash and Shi, Weidong},
  title = {SAMAF: Sequence-to-sequence Autoencoder Model for Audio Fingerprinting},
  year = {2020},
  issue_date = {May 2020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {16},
  number = {2},
  issn = {1551-6857},
  url = {https://doi.org/10.1145/3380828},
  doi = {10.1145/3380828},
  abstract = {Audio fingerprinting techniques were developed to index and retrieve audio samples by comparing a content-based compact signature of the audio instead of the entire audio sample, thereby reducing memory and computational expense. Different techniques have been applied to create audio fingerprints; however, with the introduction of deep learning, new data-driven unsupervised approaches are available. This article presents Sequence-to-Sequence Autoencoder Model for Audio Fingerprinting (SAMAF), which improved hash generation through a novel loss function composed of terms: Mean Square Error, minimizing the reconstruction error; Hash Loss, minimizing the distance between similar hashes and encouraging clustering; and Bitwise Entropy Loss, minimizing the variation inside the clusters. The performance of the model was assessed with a subset of VoxCeleb1 dataset, a“speech in-the-wild” dataset. Furthermore, the model was compared against three baselines: Dejavu, a Shazam-like algorithm; Robust Audio Fingerprinting System (RAFS), a Bit Error Rate (BER) methodology robust to time-frequency distortions and coding/decoding transformations; and Panako, a constellation-based algorithm adding time-frequency distortion resilience. Extensive empirical evidence showed that our approach outperformed all the baselines in the audio identification task and other classification tasks related to the attributes of the audio signal with an economical hash size of either 128 or 256 bits for one second of audio.},
  journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
  month = may,
  articleno = {43},
  numpages = {23},
  keywords = {sequence-to-sequence autoencoder, audio identification, audio fingerprinting, Deep learning}
}